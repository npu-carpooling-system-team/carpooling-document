<div align="center">
    <h1>
        项目经验(?)
    </h1>
</div>



这个项目之所以后端坚持上分布式与微服务就是希望能够通过亲自上手的方式来加强记忆，同时提升熟练度。很多坑不自己踩过是永远不会了解的。这篇文档存在的意义就是记录一下遇到的一些问题、



## 1. 长事务

周二的时候做到了拼车行程搜索模块，很熟悉的架构

```mermaid
graph LR
	A((前端)) --> 新增/修改信息
	新增/修改信息 --> 后端网关/服务
	后端网关/服务 --> MySQL
	MySQL --> ElasticSearch
	A --> 搜索信息
	搜索信息 --> ElasticSearch
```

在这层MySQL和ElasticSearch之间就存在着分布式事务的问题。将这整个流程直接写在一个方法线程中显然是不可取的。整个事务会显得非常冗长，前端用户的体验极差。

解决的方法有两种：

+ 我的歪门邪道是因为确实只有两个任务需要同时进行，因此可以同时开两个线程来执行两地的任务。为了保证新开线程的事务一致性，可以另起一个`@Service`，也可以使用获取回调并手动提交的方式。

+ 学成在线中对类似情况的解决方案

  详见学成在线第4章讲义

  ![image-20230420205013682](https://cdn.jsdelivr.net/gh/WangMinan/Pics/image-20230420205013682.png)





## 2. 多线程事务

回到事务的核心概念上来，事务具有ACID属性

+ 原子性（Atomicity）
  原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，
+ 一致性（Consistency）
  一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。
+ 隔离性（Isolation）
  隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
+ 持久性（Durability）
  持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

首先应当指出的常见知识空缺如下:

+ **ElasticSearch不支持事务**，我们从底层来说，那就是基于Segment的Lucene的单一translog和MySQL的三log不同，而在InnoDB事务中起关键作用的就是undolog和redolog，ES显然缺乏这样的机制。

  有关三大日志，尤其是undolog，请看[MySQL三大日志(binlog、redo log和undo log)详解 | JavaGuide(Java面试 + 学习指南)](https://javaguide.cn/database/mysql/mysql-logs.html#undo-log)

  因此我们主要采用的解决方案如下

  ![image-20230513104443851](https://cdn.jsdelivr.net/gh/WangMinan/Pics/image-20230513104443851.png)

+ **Redis的事务不具备ACID属性**。Redis中的事务是一种将多个命令打包成一个原子性操作，并确保该操作在执行过程中不会被其他客户端或线程中断的机制。具体涉及到RDB,AOF与混合持久化机制并没有提供事务操作。[Redis持久化机制详解 | JavaGuide(Java面试 + 学习指南)](https://javaguide.cn/database/redis/redis-persistence.html)

所以我们在上一个长事务案例中把MySQL与Redis+ES操作分离在两个线程上，MySQL操作位于主线程且开启注解型事务的方式属于歪打正着。确实只有MySQL需要进行事务管理，**新开线程中的操作不需要被事务管理**。而且在新线程上执行事务管理意味着我们需要等待新线程返回后才能最终将结果返回给用户，这样的做法就违背了我们为了快速返回结果而使用多线程操作的初衷了。

但是话说回来，如果两个线程上确实需要同步执行事务管理时又应当如何解决呢？

面对多线程事务肯定不能再用注解式事务来处理了，AOP已经解决不了问题了。我觉得不用多说什么原理上的内容了，主要是通过`countDownLatch`配合实现的

![image-20230513111014040](https://cdn.jsdelivr.net/gh/WangMinan/Pics/image-20230513111014040.png)

> 再以 `CountDownLatch` 以例，任务分为 N 个子线程去执行，`state` 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后`countDown()` 一次，state 会 CAS(Compare and Swap) 减 1。等到所有子线程都执行完后(即 `state=0` )，会 `unpark()` 主调用线程，然后主调用线程就会从 `await()` 函数返回，继续后余动作。

以下是一个向数据库更新教师信息的方法，由于采用了**在一堆update之后手动提交**，避免了每一次update就提交事务(框架隐藏性事务)，因此在海量数据下能极大提高写入性能。缺点是一旦出现问题后所有操作都回滚。

```java
@Service
public class StudentServiceImpl implements StudentService {
    @Autowired
    private StudentMapper studentMapper;

    @Autowired
    private DataSourceTransactionManager dataSourceTransactionManager;

    @Autowired
    private TransactionDefinition transactionDefinition;

    @Override
    public void updateStudents(List<Student> students, CountDownLatch threadLatch) {
        TransactionStatus transactionStatus = dataSourceTransactionManager.getTransaction(transactionDefinition);
        System.out.println("子线程：" + Thread.currentThread().getName());
        try {
            students.forEach(s -> {
                // 更新教师信息
                // String teacher = s.getTeacher();
                String newTeacher = "TNO_" + new Random().nextInt(100);
                s.setTeacher(newTeacher);
                studentMapper.update(s);
            });
            dataSourceTransactionManager.commit(transactionStatus);
            threadLatch.countDown();
        } catch (Throwable e) {
            e.printStackTrace();
            dataSourceTransactionManager.rollback(transactionStatus);
        }
    }
}
```

我们可以看到在完成了一次批处理后`CountDownLatch`下降1

创建线程池并在多线程中调用`updateStudents`的代码如下

```java
@Autowired
private DataSourceTransactionManager dataSourceTransactionManager;

@Autowired
private TransactionDefinition transactionDefinition;

@Autowired
private StudentService studentService;

/**
 * 对用户而言，27s 任是一个较长的时间，我们尝试用多线程的方式来经行修改操作看能否加快处理速度
 * 预计创建10个线程，每个线程进行5000条数据修改操作
 * 耗时统计
 * 1 线程数：1      耗时：25s
 * 2 线程数：2      耗时：14s
 * 3 线程数：5      耗时：15s
 * 4 线程数：10     耗时：15s
 * 5 线程数：100    耗时：15s
 * 6 线程数：200    耗时：15s
 * 7 线程数：500    耗时：17s
 * 8 线程数：1000    耗时：19s
 * 8 线程数：2000    耗时：23s
 * 8 线程数：5000    耗时：29s
 */
@Test
void updateStudentWithThreads() {
    //查询总数据
    List<Student> allStudents = studentMapper.getAll();
    // 线程数量
    final Integer threadCount = 100;

    //每个线程处理的数据量
    final Integer dataPartionLength = (allStudents.size() + threadCount - 1) / threadCount;

    // 创建多线程处理任务
    ExecutorService studentThreadPool = Executors.newFixedThreadPool(threadCount);
    CountDownLatch threadLatchs = new CountDownLatch(threadCount);

    for (int i = 0; i < threadCount; i++) {
        // 每个线程处理的数据
        List<Student> threadDatas = allStudents.stream()
                .skip(i * dataPartionLength).limit(dataPartionLength).collect(Collectors.toList());
        studentThreadPool.execute(() -> {
            studentService.updateStudents(threadDatas, threadLatchs);
        });
    }
    try {
        // 倒计时锁设置超时时间 30s
        threadLatchs.await(30, TimeUnit.SECONDS);
    } catch (Throwable e) {
        e.printStackTrace();
    }

    System.out.println("主线程完成");
}
```

这样就完成了基础的多线程事务。

对上述代码当然还可以做进一步优化，具体是参考这篇[面试官：Java 多线程怎么做事务控制？一半人答不上来。。-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2057510) 写得还不错。



## 3. 分布式事务

详见黑马微服务课程高级篇Seata的部分。详细讲述了ACP原则与Seata的四种模式

人家已经写好轮子了我们就不造轮子了。



## 4. Jackson序列化Object异常

Jackson在执行`objectMapper.convertValue`操作时报出Cannot construct instance of (although at least one Creator exists)异常

需要为被其转换的类加上如下构造

```java
public LoginAccount(String json) throws IOException {
        LoginAccount loginAccount = new ObjectMapper().readValue(json, LoginAccount.class);
        this.id = loginAccount.getId();
        this.username = loginAccount.getUsername();
        this.password = loginAccount.getPassword();
        this.role = loginAccount.getRole();
        this.isDeleted = loginAccount.getIsDeleted();
}
```

或者 使用 `ObjectMapper.readValue()` 代替 `ObjectMapper.convertValue()` 对JSON数据进行反转

这两个方法的主要区别在于，`readValue`方法需要将JSON字符串作为参数传递，而`convertValue`方法需要将JSON对象作为参数传递。此外，`readValue`方法可以将JSON字符串转换为Java对象的任何类型，而`convertValue`方法只能将JSON对象转换为指定类型的Java对象。

在类出现继承关系时请及时注意框定需要转换的字段范围。需要将父类的字段标记为已排除字段，避免出现构造方法的引用问题。

最终的`LoginAccount`类如下所示

```java
package edu.npu.entity;

import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.databind.ObjectMapper;
import edu.npu.common.RoleEnum;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.springframework.security.core.GrantedAuthority;
import org.springframework.security.core.authority.SimpleGrantedAuthority;
import org.springframework.security.core.userdetails.UserDetails;

import java.io.IOException;
import java.io.Serial;
import java.io.Serializable;
import java.util.Collection;
import java.util.List;
import java.util.Objects;

/**
 * 用于用户名密码登录所需表格
 */
@Data
@NoArgsConstructor
@AllArgsConstructor
// 排除UserDetails的参数。这些参数不需要被存到Redis中，可以直接通过本类中方法生成
@JsonIgnoreProperties(
        value = {"accountNonExpired", "accountNonLocked",
                "credentialsNonExpired", "enabled", "authorities"})
@JsonInclude(JsonInclude.Include.NON_NULL)
public class LoginAccount implements Serializable, UserDetails {
    /**
     * 用户登录时唯一编号
     */
    private Long id;

    /**
     * 用户登录名/用户手机号
     */
    private String username;

    /**
     * 用户登录密码
     */
    private String password;

    /**
     * 用户角色:司机/乘客,管理员
     */
    private int role;

    /**
     * 逻辑删除字段,0未删除,1已删除
     */
    private Integer isDeleted;

    @Serial
    private static final long serialVersionUID = 184688L;

    @Override
    public Collection<? extends GrantedAuthority> getAuthorities() {
        return List.of(new SimpleGrantedAuthority(
                Objects.requireNonNull(RoleEnum.fromValue(role)).name()));
    }

    @Override
    public boolean isAccountNonExpired() {
        return true;
    }

    @Override
    public boolean isAccountNonLocked() {
        return isDeleted == 0;
    }

    @Override
    public boolean isCredentialsNonExpired() {
        return true;
    }

    @Override
    public boolean isEnabled() {
        return true;
    }

    // 需要手动准备如下构造函数供Jackson调用 否则报Cannot construct instance of
    public LoginAccount(String json) throws IOException{
        LoginAccount loginAccount = new ObjectMapper().readValue(json, LoginAccount.class);
        this.id = loginAccount.getId();
        this.username = loginAccount.getUsername();
        this.password = loginAccount.getPassword();
        this.role = loginAccount.getRole();
        this.isDeleted = loginAccount.getIsDeleted();
    }
}
```



## 5. 价格计算

这次项目中的价格部分确实是进行了简化的。

关于存价格这件事一般有俩解决方案

+ 所有价格都用int存，表示分位，计算时也按照分的逻辑进行运算，如果实在需要按照元的情况进行计算了(如向支付宝发送请求时)再进行转换。我个人认为这种方案是稳妥的，能够规避大量的精度问题。
+ 使用decimal，包括在Java端使用`BigDecimal`，在MySQL端`decimal`类型来存储价格数据。能尽量从数据类型的角度上来规避精度丢失问题。



## 6. Redis哨兵集群

我的Redis满打满算只有三台，跑不起来多主多从的cluster。勉强跑一个sentinel来给这个项目助助兴。

基于[基于 Docker 的 Redis 高可用集群搭建](https://zhuanlan.zhihu.com/p/70592387)与[黑马程序员微服务课程高级篇Redis讲](https://www.bilibili.com/video/BV1LQ4y127n4/)，本项目主要为了实验搭建的Redis集群。

集群拓扑如下所示

![redis_sentinel](https://wangminan-files.oss-cn-hongkong.aliyuncs.com/picBed/redis_sentinel.png)

当前的主节点为华为云ECS服务器。负责所有数据写入工作。

使用`info`命令查看节点信息可得

```properties
# Replication
role:master
connected_slaves:2
slave0:ip=121.41.227.153,port=6379,state=online,offset=3161003,lag=0
slave1:ip=8.218.84.229,port=6379,state=online,offset=3161003,lag=0
master_failover_state:no-failover
master_replid:e40d5214d82edaf1b2255ca3e3960bdaaf80867a
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:3161142
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:2112567
repl_backlog_histlen:1048576
```

了解到其余两个节点都是从节点

当Redis服务器的主节点华为云ECS主观失能时(大于等于$[3/2] + 1 = 1 + 1 = 2$个sentinel节点与未获取到master心跳时)，sentinel将根据权重自动选择可用的slave节点，作为新的master，同时通知原本的master已产生新的主节点。

与分片模式不同，该集群中每个节点都拥有相同的数据(基于操作流同步实现)。

在使用`spring-boot-starter-data-redis`连接集群时，我大概踩了一万个坑。最终试验后得出在`SpringBoot3.1`的情况下应该做的工作如下列举。

+ 使用maven引入依赖。坐标为

  ```xml
  <dependency>
          <groupId>org.springframework.boot</groupId>
          <artifactId>spring-boot-starter-data-redis</artifactId>
  </dependency>
  ```

+ 写配置文件。关于lettuce连接池的调优本文不涉及，请另行查看资料

  ```yaml
  spring:
    data:
      redis:
        lettuce:
          pool:
            max-active: 8
            max-idle: 8
            max-wait: -1ms
            min-idle: 0
        sentinel:
          password: npu2020302598
          master: mymaster
          nodes:
            - 60.204.153.158:27001
            - 60.204.153.158:27002
            - 60.204.153.158:27003
        database: 0
        timeout: 6000ms
        password: npu2020302598
  ```

  注意：下列条件不满足时Redis连接失败

  + sentinel节点若有密码应当保持一致，在`spring.data.redis.sentinel.password`中给出
  + Redis服务器节点若有密码也应保持一致，需要在`spring.data.redis.password`中给出
  + 请不要随便改动上述配置的顺序。这是个很玄学的问题，但就是这样。顺序变动后可能会出现连接问题。

+ 写配置类。我们希望slave节点负责主要的读工作，而master节点负责所有的写工作，则配置类如下

  ```java
  package edu.npu.config;
  
  import io.lettuce.core.ReadFrom;
  import org.springframework.boot.autoconfigure.data.redis.LettuceClientConfigurationBuilderCustomizer;
  import org.springframework.context.annotation.Bean;
  import org.springframework.context.annotation.Configuration;
  
  /**
   * @author : [wangminan]
   * @description : [Redis配置类]
   */
  @Configuration
  public class RedisConfig {
      @Bean
      public LettuceClientConfigurationBuilderCustomizer customizer() {
          return clientConfigurationBuilder -> clientConfigurationBuilder
                  // 优先读slave 所有slave节点都不可用才读master
                  .readFrom(ReadFrom.REPLICA_PREFERRED);
      }
  }
  ```

  其中，`ReadFrom`是一个枚举类。

  ```java
  /**
   * Setting to read from the upstream only.
   */
  public static final ReadFrom MASTER = new ReadFromImpl.ReadFromUpstream();
  
  /**
   * Setting to read preferred from the upstream and fall back to a replica if the master is not available.
   */
  public static final ReadFrom MASTER_PREFERRED = new ReadFromImpl.ReadFromUpstreamPreferred();
  
  /**
   * Setting to read from the upstream only.
   *
   * @since 6.0
   */
  public static final ReadFrom UPSTREAM = new ReadFromImpl.ReadFromUpstream();
  
  /**
   * Setting to read preferred from the upstream and fall back to a replica if the upstream is not available.
   *
   * @since 6.0
   */
  public static final ReadFrom UPSTREAM_PREFERRED = new ReadFromImpl.ReadFromUpstreamPreferred();
  
  /**
   * Setting to read preferred from replica and fall back to upstream if no replica is available.
   *
   * @since 5.2
   */
  public static final ReadFrom REPLICA_PREFERRED = new ReadFromImpl.ReadFromReplicaPreferred();
  
  /**
   * Setting to read preferred from replicas and fall back to upstream if no replica is available.
   *
   * @since 4.4
   * @deprecated Renamed to {@link #REPLICA_PREFERRED}.
   */
  @Deprecated
  public static final ReadFrom SLAVE_PREFERRED = REPLICA_PREFERRED;
  
  /**
   * Setting to read from the replica only.
   *
   * @since 5.2
   */
  public static final ReadFrom REPLICA = new ReadFromImpl.ReadFromReplica();
  
  /**
   * Setting to read from the replica only.
   *
   * @deprecated renamed to {@link #REPLICA}.
   */
  @Deprecated
  public static final ReadFrom SLAVE = REPLICA;
  
  /**
   * Setting to read from the node with the lowest latency during topology discovery. Note that latency measurements are
   * momentary snapshots that can change in rapid succession. Requires dynamic refresh sources to obtain topologies and
   * latencies from all nodes in the cluster.
   *
   * @since 6.1.7
   */
  public static final ReadFrom LOWEST_LATENCY = new ReadFromImpl.ReadFromLowestCommandLatency();
  
  /**
   * Setting to read from the node with the lowest latency during topology discovery. Note that latency measurements are
   * momentary snapshots that can change in rapid succession. Requires dynamic refresh sources to obtain topologies and
   * latencies from all nodes in the cluster.
   *
   * @deprecated since 6.1.7 as we're renaming this setting to {@link #LOWEST_LATENCY} for more clarity what this setting
   *             actually represents.
   */
  @Deprecated
  public static final ReadFrom NEAREST = LOWEST_LATENCY;
  
  /**
   * Setting to read from any node.
   *
   * @since 5.2
   */
  public static final ReadFrom ANY = new ReadFromImpl.ReadFromAnyNode();
  
  /**
   * Setting to read from any replica node.
   *
   * @since 6.0.1
   */
  public static final ReadFrom ANY_REPLICA = new ReadFromImpl.ReadFromAnyReplica();
  ```

  由此可见我们如果希望使用延迟最低的情况也可以使用`LOWEST_LATENCY`
